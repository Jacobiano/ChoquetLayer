{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f1e2c1-b6cd-4fb0-908f-87b1ccee6122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n",
      "listIm.shape (4048, 128, 128)\n",
      "listImVal.shape (512, 128, 128)\n",
      "listY.shape (4048, 1)\n",
      "listYVal.shape (512, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Layer\n",
    "from skimage.io import imread\n",
    "from shutil import copyfile\n",
    "#import tensorflow_probability as tfp\n",
    "print(tf.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.gray()\n",
    "from sklearn.metrics import accuracy_score\n",
    "#import tensorflow_probability as tfp\n",
    "import random\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "BATCH_SIZE = int(32.)\n",
    "EPOCHS = int(512.)\n",
    "\n",
    "batch_size = BATCH_SIZE\n",
    "epochs = EPOCHS\n",
    "learning_rate=0.001\n",
    "CHANNELS=1\n",
    "NLAYERS=3\n",
    "SHRINK=1\n",
    "NFILTERS=48\n",
    "KSIZE=13\n",
    "SUBSPACE=12\n",
    "PATIENCE_ES=40\n",
    "PATIENCE_RP=5\n",
    "\n",
    "\n",
    "class NeymanScott:\n",
    "    \"\"\"\n",
    "    Neyman-Scott point process using a Poisson variable for the number of parent points, uniform for\n",
    "    the number of daughter points and Pareto distribution for the distance from the daughter points to\n",
    "    the parent.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 poisson_mean: float,\n",
    "                 daughter_max: int,\n",
    "                 pareto_alpha: float,\n",
    "                 pareto_scale: float,\n",
    "                 size: (int, int)):\n",
    "        \"\"\"\n",
    "        :param poisson_mean: mean of the number of parent points\n",
    "        :param daughter_max: maximum number of daughters per parent points\n",
    "        :param pareto_alpha: alpha parameter of the Pareto distribution\n",
    "        :param pareto_scale: scale used in the Pareto distribution. This parameter is\n",
    "            applied before resizing the points from the [0, 1] interval to the size of the image.\n",
    "        :param size: rescale the output to this size\n",
    "        \"\"\"\n",
    "        self.poisson_mean = poisson_mean\n",
    "        self.daughter_max = daughter_max\n",
    "        self.pareto_alpha = pareto_alpha\n",
    "        self.pareto_scale = pareto_scale\n",
    "        self.size = np.array([size])\n",
    "        self.generator = np.random.Generator(np.random.PCG64())\n",
    "\n",
    "    def __call__(self):\n",
    "        num_parents = self.generator.poisson(lam=self.poisson_mean)\n",
    "        parents = self.generator.random((num_parents, 2))\n",
    "        num_daughters = self.generator.integers(1, self.daughter_max, num_parents)\n",
    "        points = np.empty((0, 2))\n",
    "\n",
    "        for i in range(num_parents):\n",
    "            # normalizes the pareto II distribution\n",
    "            dist = self.generator.pareto(self.pareto_alpha, (num_daughters[i], 1))\n",
    "            dist = (dist + 1) * self.pareto_scale\n",
    "            angle = self.generator.uniform(0., 2 * np.pi, (num_daughters[i],))\n",
    "            positions = np.stack([np.cos(angle), np.sin(angle)], 1)\n",
    "            positions *= dist\n",
    "            positions += parents[i, np.newaxis, :]\n",
    "            points = np.concatenate([points, positions])\n",
    "        # remove points outside the set [0, 1] x [0, 1]\n",
    "        valid_points = np.logical_and(\n",
    "            np.logical_and(0. <= points[:, 0], points[:, 0] <= 1.),\n",
    "            np.logical_and(0. <= points[:, 1], points[:, 1] <= 1.)\n",
    "        )\n",
    "        points = points[valid_points, :]\n",
    "        # scale to the image size\n",
    "        points = points * self.size\n",
    "        return points\n",
    "\n",
    "\n",
    "\n",
    "NSAMPLES_TRAINING=2024*2\n",
    "IMG_SIZE=128\n",
    "\n",
    "poisson_mean=100\n",
    "daughter_max=50\n",
    "pareto_scale=.02\n",
    "pareto_alpha=1. #GENERATION ON IT\n",
    "gen = NeymanScott(poisson_mean, daughter_max, pareto_alpha, pareto_scale, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "generatedata=1\n",
    "if generatedata==1:\n",
    "    listIm=[]\n",
    "    listY=[]\n",
    "    for i in range(NSAMPLES_TRAINING):\n",
    "        pareto_alpha=gen.generator.random(1)*10\n",
    "        gen = NeymanScott(poisson_mean, daughter_max, pareto_alpha, pareto_scale, (IMG_SIZE, IMG_SIZE))\n",
    "        points = gen()\n",
    "        I=np.zeros([IMG_SIZE,IMG_SIZE])\n",
    "        I[np.int64(np.floor(points[:, 0])), np.int64(np.floor(points[:, 1]))]=1\n",
    "        listIm.append(I)\n",
    "        listY.append(pareto_alpha)\n",
    "    listIm=np.stack(listIm)\n",
    "    listY=np.stack(listY)\n",
    "\n",
    "    NSAMPLES_VALIDATION=512\n",
    "    listImVal=[]\n",
    "    listYVal=[]\n",
    "    for i in range(NSAMPLES_VALIDATION):\n",
    "        pareto_alpha=gen.generator.random(1)*10\n",
    "        gen = NeymanScott(poisson_mean, daughter_max, pareto_alpha, pareto_scale, (IMG_SIZE, IMG_SIZE))\n",
    "        points = gen()\n",
    "        I=np.zeros([IMG_SIZE,IMG_SIZE])\n",
    "        I[np.int64(np.floor(points[:, 0])), np.int64(np.floor(points[:, 1]))]=1\n",
    "        listImVal.append(I)\n",
    "        listYVal.append(pareto_alpha)\n",
    "\n",
    "    listImVal=np.stack(listImVal)\n",
    "    listYVal=np.stack(listYVal)\n",
    "    np.save('listIm.npy',listIm)\n",
    "    np.save('listImVal.npy',listImVal)\n",
    "    np.save('listY.npy',listY)\n",
    "    np.save('listYVal.npy',listYVal)\n",
    "else:\n",
    "    listIm=np.load('listIm.npy')\n",
    "    listImVal=np.load('listImVal.npy')\n",
    "    listY=np.load('listY.npy')\n",
    "    listYVal=np.load('listYVal.npy')\n",
    "\n",
    "print('listIm.shape',listIm.shape)\n",
    "print('listImVal.shape',listImVal.shape)\n",
    "print('listY.shape',listY.shape)\n",
    "print('listYVal.shape',listYVal.shape)\n",
    "\n",
    "listY=listY/9\n",
    "listYVal=listYVal/9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66fdff72-ce5c-4e78-b214-887827dc0df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 16:39:40.240165: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2023-10-02 16:39:40.240180: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-10-02 16:39:40.240185: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-10-02 16:39:40.240214: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-02 16:39:40.240229: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 128, 48)      480       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 48)      20784     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 128, 128, 48)      20784     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 128, 128, 48)      2352      \n",
      "                                                                 \n",
      " depthwise_conv2d (Depthwis  (None, 128, 128, 48)      8160      \n",
      " eConv2D)                                                        \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 48)                0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 48)                192       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12)                588       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                156       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53509 (209.02 KB)\n",
      "Trainable params: 53413 (208.64 KB)\n",
      "Non-trainable params: 96 (384.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53509\n",
      "Epoch 1/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 16:39:41.841169: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - ETA: 0s - loss: 0.1178 - mse: 0.0251 - mae: 0.1178"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 16:40:18.252275: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 38s 267ms/step - loss: 0.1178 - mse: 0.0251 - mae: 0.1178 - val_loss: 0.5829 - val_mse: 0.4377 - val_mae: 0.5829 - lr: 0.0010\n",
      "Epoch 2/512\n",
      "127/127 [==============================] - 31s 245ms/step - loss: 0.1049 - mse: 0.0181 - mae: 0.1049 - val_loss: 0.5538 - val_mse: 0.3978 - val_mae: 0.5538 - lr: 0.0010\n",
      "Epoch 3/512\n",
      "127/127 [==============================] - 31s 246ms/step - loss: 0.1072 - mse: 0.0207 - mae: 0.1072 - val_loss: 0.4430 - val_mse: 0.2412 - val_mae: 0.4430 - lr: 0.0010\n",
      "Epoch 4/512\n",
      "127/127 [==============================] - 31s 245ms/step - loss: 0.1007 - mse: 0.0171 - mae: 0.1007 - val_loss: 0.5117 - val_mse: 0.3243 - val_mae: 0.5117 - lr: 0.0010\n",
      "Epoch 5/512\n",
      "127/127 [==============================] - 31s 245ms/step - loss: 0.0893 - mse: 0.0129 - mae: 0.0893 - val_loss: 0.3481 - val_mse: 0.1416 - val_mae: 0.3481 - lr: 0.0010\n",
      "Epoch 6/512\n",
      "127/127 [==============================] - 31s 245ms/step - loss: 0.0850 - mse: 0.0117 - mae: 0.0850 - val_loss: 0.1816 - val_mse: 0.0419 - val_mae: 0.1816 - lr: 0.0010\n",
      "Epoch 7/512\n",
      "127/127 [==============================] - 3091s 25s/step - loss: 0.0827 - mse: 0.0106 - mae: 0.0827 - val_loss: 0.2535 - val_mse: 0.0839 - val_mae: 0.2535 - lr: 0.0010\n",
      "Epoch 8/512\n",
      "127/127 [==============================] - 4156s 33s/step - loss: 0.0854 - mse: 0.0117 - mae: 0.0854 - val_loss: 0.1650 - val_mse: 0.0389 - val_mae: 0.1650 - lr: 0.0010\n",
      "Epoch 9/512\n",
      "127/127 [==============================] - 4550s 36s/step - loss: 0.0814 - mse: 0.0107 - mae: 0.0814 - val_loss: 0.0935 - val_mse: 0.0135 - val_mae: 0.0935 - lr: 0.0010\n",
      "Epoch 10/512\n",
      "127/127 [==============================] - 4189s 33s/step - loss: 0.0885 - mse: 0.0125 - mae: 0.0885 - val_loss: 0.3529 - val_mse: 0.1460 - val_mae: 0.3529 - lr: 0.0010\n",
      "Epoch 11/512\n",
      "127/127 [==============================] - 4836s 38s/step - loss: 0.0857 - mse: 0.0117 - mae: 0.0857 - val_loss: 0.1596 - val_mse: 0.0309 - val_mae: 0.1596 - lr: 0.0010\n",
      "Epoch 12/512\n",
      "127/127 [==============================] - 4064s 32s/step - loss: 0.0898 - mse: 0.0127 - mae: 0.0898 - val_loss: 0.4858 - val_mse: 0.2947 - val_mae: 0.4858 - lr: 0.0010\n",
      "Epoch 13/512\n",
      "127/127 [==============================] - 4217s 33s/step - loss: 0.0903 - mse: 0.0132 - mae: 0.0903 - val_loss: 0.5236 - val_mse: 0.3481 - val_mae: 0.5236 - lr: 0.0010\n",
      "Epoch 14/512\n",
      "127/127 [==============================] - 4714s 37s/step - loss: 0.1164 - mse: 0.0249 - mae: 0.1164 - val_loss: 0.5877 - val_mse: 0.4446 - val_mae: 0.5877 - lr: 0.0010\n",
      "Epoch 15/512\n",
      "127/127 [==============================] - 5675s 45s/step - loss: 0.1094 - mse: 0.0205 - mae: 0.1094 - val_loss: 0.5700 - val_mse: 0.4149 - val_mae: 0.5700 - lr: 1.0000e-04\n",
      "Epoch 16/512\n",
      "127/127 [==============================] - 5018s 40s/step - loss: 0.0837 - mse: 0.0114 - mae: 0.0837 - val_loss: 0.3261 - val_mse: 0.1237 - val_mae: 0.3261 - lr: 1.0000e-04\n",
      "Epoch 17/512\n",
      "127/127 [==============================] - 4413s 35s/step - loss: 0.0743 - mse: 0.0090 - mae: 0.0743 - val_loss: 0.1923 - val_mse: 0.0486 - val_mae: 0.1923 - lr: 1.0000e-04\n",
      "Epoch 18/512\n",
      "127/127 [==============================] - 6067s 48s/step - loss: 0.0731 - mse: 0.0086 - mae: 0.0731 - val_loss: 0.1770 - val_mse: 0.0412 - val_mae: 0.1770 - lr: 1.0000e-04\n",
      "Epoch 19/512\n",
      "127/127 [==============================] - 4819s 38s/step - loss: 0.0752 - mse: 0.0091 - mae: 0.0752 - val_loss: 0.0989 - val_mse: 0.0154 - val_mae: 0.0989 - lr: 1.0000e-04\n",
      "Epoch 20/512\n",
      "127/127 [==============================] - 4546s 36s/step - loss: 0.0731 - mse: 0.0087 - mae: 0.0731 - val_loss: 0.0728 - val_mse: 0.0089 - val_mae: 0.0728 - lr: 1.0000e-05\n",
      "Epoch 21/512\n",
      "127/127 [==============================] - 5433s 43s/step - loss: 0.0731 - mse: 0.0088 - mae: 0.0731 - val_loss: 0.0666 - val_mse: 0.0075 - val_mae: 0.0666 - lr: 1.0000e-05\n",
      "Epoch 22/512\n",
      "127/127 [==============================] - 4304s 34s/step - loss: 0.0721 - mse: 0.0086 - mae: 0.0721 - val_loss: 0.0633 - val_mse: 0.0069 - val_mae: 0.0633 - lr: 1.0000e-05\n",
      "Epoch 23/512\n",
      "127/127 [==============================] - 5034s 40s/step - loss: 0.0730 - mse: 0.0088 - mae: 0.0730 - val_loss: 0.0627 - val_mse: 0.0068 - val_mae: 0.0627 - lr: 1.0000e-05\n",
      "Epoch 24/512\n",
      "127/127 [==============================] - 5300s 42s/step - loss: 0.0744 - mse: 0.0092 - mae: 0.0744 - val_loss: 0.0635 - val_mse: 0.0068 - val_mae: 0.0635 - lr: 1.0000e-05\n",
      "Epoch 25/512\n",
      "127/127 [==============================] - 3665s 29s/step - loss: 0.0734 - mse: 0.0088 - mae: 0.0734 - val_loss: 0.0636 - val_mse: 0.0069 - val_mae: 0.0636 - lr: 1.0000e-05\n",
      "Epoch 26/512\n",
      "127/127 [==============================] - 5615s 45s/step - loss: 0.0740 - mse: 0.0089 - mae: 0.0740 - val_loss: 0.0630 - val_mse: 0.0068 - val_mae: 0.0630 - lr: 1.0000e-05\n",
      "Epoch 27/512\n",
      "127/127 [==============================] - 5361s 43s/step - loss: 0.0717 - mse: 0.0084 - mae: 0.0717 - val_loss: 0.0630 - val_mse: 0.0068 - val_mae: 0.0630 - lr: 1.0000e-05\n",
      "Epoch 28/512\n",
      "127/127 [==============================] - 4604s 37s/step - loss: 0.0715 - mse: 0.0084 - mae: 0.0715 - val_loss: 0.0641 - val_mse: 0.0070 - val_mae: 0.0641 - lr: 1.0000e-05\n",
      "Epoch 29/512\n",
      "127/127 [==============================] - 5574s 44s/step - loss: 0.0737 - mse: 0.0089 - mae: 0.0737 - val_loss: 0.0635 - val_mse: 0.0069 - val_mae: 0.0635 - lr: 1.0000e-06\n",
      "Epoch 30/512\n",
      "127/127 [==============================] - 4465s 35s/step - loss: 0.0750 - mse: 0.0092 - mae: 0.0750 - val_loss: 0.0638 - val_mse: 0.0069 - val_mae: 0.0638 - lr: 1.0000e-06\n",
      "Epoch 31/512\n",
      "127/127 [==============================] - 5601s 44s/step - loss: 0.0718 - mse: 0.0086 - mae: 0.0718 - val_loss: 0.0636 - val_mse: 0.0069 - val_mae: 0.0636 - lr: 1.0000e-06\n",
      "Epoch 32/512\n",
      "127/127 [==============================] - 5887s 47s/step - loss: 0.0734 - mse: 0.0087 - mae: 0.0734 - val_loss: 0.0634 - val_mse: 0.0069 - val_mae: 0.0634 - lr: 1.0000e-06\n",
      "Epoch 33/512\n",
      "127/127 [==============================] - 5991s 48s/step - loss: 0.0740 - mse: 0.0090 - mae: 0.0740 - val_loss: 0.0636 - val_mse: 0.0069 - val_mae: 0.0636 - lr: 1.0000e-06\n",
      "Epoch 34/512\n",
      "127/127 [==============================] - 5185s 41s/step - loss: 0.0721 - mse: 0.0085 - mae: 0.0721 - val_loss: 0.0636 - val_mse: 0.0069 - val_mae: 0.0636 - lr: 1.0000e-06\n",
      "Epoch 35/512\n",
      "127/127 [==============================] - 4923s 39s/step - loss: 0.0731 - mse: 0.0087 - mae: 0.0731 - val_loss: 0.0634 - val_mse: 0.0069 - val_mae: 0.0634 - lr: 1.0000e-06\n",
      "Epoch 36/512\n",
      "127/127 [==============================] - 3231s 26s/step - loss: 0.0721 - mse: 0.0085 - mae: 0.0721 - val_loss: 0.0634 - val_mse: 0.0069 - val_mae: 0.0634 - lr: 1.0000e-06\n",
      "Epoch 37/512\n",
      "127/127 [==============================] - 4125s 33s/step - loss: 0.0725 - mse: 0.0086 - mae: 0.0725 - val_loss: 0.0634 - val_mse: 0.0069 - val_mae: 0.0634 - lr: 1.0000e-06\n",
      "Epoch 38/512\n",
      "127/127 [==============================] - 4917s 39s/step - loss: 0.0735 - mse: 0.0089 - mae: 0.0735 - val_loss: 0.0635 - val_mse: 0.0069 - val_mae: 0.0635 - lr: 1.0000e-06\n",
      "Epoch 39/512\n",
      "127/127 [==============================] - 5520s 44s/step - loss: 0.0726 - mse: 0.0087 - mae: 0.0726 - val_loss: 0.0636 - val_mse: 0.0069 - val_mae: 0.0636 - lr: 1.0000e-06\n",
      "Epoch 40/512\n",
      "127/127 [==============================] - 4420s 35s/step - loss: 0.0723 - mse: 0.0085 - mae: 0.0723 - val_loss: 0.0637 - val_mse: 0.0069 - val_mae: 0.0637 - lr: 1.0000e-06\n",
      "Epoch 41/512\n",
      "127/127 [==============================] - 4697s 37s/step - loss: 0.0729 - mse: 0.0086 - mae: 0.0729 - val_loss: 0.0635 - val_mse: 0.0069 - val_mae: 0.0635 - lr: 1.0000e-06\n",
      "Epoch 42/512\n",
      "127/127 [==============================] - 5537s 44s/step - loss: 0.0752 - mse: 0.0092 - mae: 0.0752 - val_loss: 0.0636 - val_mse: 0.0069 - val_mae: 0.0636 - lr: 1.0000e-06\n",
      "Epoch 43/512\n",
      "127/127 [==============================] - 3293s 26s/step - loss: 0.0731 - mse: 0.0089 - mae: 0.0731 - val_loss: 0.0638 - val_mse: 0.0069 - val_mae: 0.0638 - lr: 1.0000e-06\n",
      "Epoch 44/512\n",
      "127/127 [==============================] - 3116s 25s/step - loss: 0.0745 - mse: 0.0091 - mae: 0.0745 - val_loss: 0.0635 - val_mse: 0.0068 - val_mae: 0.0635 - lr: 1.0000e-06\n",
      "Epoch 45/512\n",
      "127/127 [==============================] - 5321s 34s/step - loss: 0.0704 - mse: 0.0081 - mae: 0.0704 - val_loss: 0.0633 - val_mse: 0.0069 - val_mae: 0.0633 - lr: 1.0000e-06\n",
      "Epoch 46/512\n",
      "127/127 [==============================] - 4719s 37s/step - loss: 0.0722 - mse: 0.0086 - mae: 0.0722 - val_loss: 0.0634 - val_mse: 0.0069 - val_mae: 0.0634 - lr: 1.0000e-06\n",
      "Epoch 47/512\n",
      "127/127 [==============================] - 4603s 37s/step - loss: 0.0737 - mse: 0.0089 - mae: 0.0737 - val_loss: 0.0635 - val_mse: 0.0069 - val_mae: 0.0635 - lr: 1.0000e-06\n",
      "Epoch 48/512\n",
      "127/127 [==============================] - 4247s 34s/step - loss: 0.0747 - mse: 0.0090 - mae: 0.0747 - val_loss: 0.0636 - val_mse: 0.0069 - val_mae: 0.0636 - lr: 1.0000e-06\n",
      "Epoch 49/512\n",
      "127/127 [==============================] - 1069s 8s/step - loss: 0.0725 - mse: 0.0086 - mae: 0.0725 - val_loss: 0.0635 - val_mse: 0.0069 - val_mae: 0.0635 - lr: 1.0000e-06\n",
      "Epoch 50/512\n",
      "127/127 [==============================] - 4668s 37s/step - loss: 0.0748 - mse: 0.0092 - mae: 0.0748 - val_loss: 0.0634 - val_mse: 0.0068 - val_mae: 0.0634 - lr: 1.0000e-06\n",
      "Epoch 51/512\n",
      "127/127 [==============================] - 4415s 35s/step - loss: 0.0756 - mse: 0.0095 - mae: 0.0756 - val_loss: 0.0635 - val_mse: 0.0069 - val_mae: 0.0635 - lr: 1.0000e-06\n",
      "Epoch 52/512\n",
      "127/127 [==============================] - 6876s 55s/step - loss: 0.0728 - mse: 0.0086 - mae: 0.0728 - val_loss: 0.0634 - val_mse: 0.0069 - val_mae: 0.0634 - lr: 1.0000e-06\n",
      "Epoch 53/512\n",
      "127/127 [==============================] - 4621s 37s/step - loss: 0.0719 - mse: 0.0085 - mae: 0.0719 - val_loss: 0.0634 - val_mse: 0.0069 - val_mae: 0.0634 - lr: 1.0000e-06\n",
      "Epoch 54/512\n",
      "127/127 [==============================] - 3578s 28s/step - loss: 0.0738 - mse: 0.0089 - mae: 0.0738 - val_loss: 0.0632 - val_mse: 0.0068 - val_mae: 0.0632 - lr: 1.0000e-06\n",
      "Epoch 55/512\n",
      "127/127 [==============================] - 5773s 46s/step - loss: 0.0730 - mse: 0.0088 - mae: 0.0730 - val_loss: 0.0634 - val_mse: 0.0069 - val_mae: 0.0634 - lr: 1.0000e-06\n",
      "Epoch 56/512\n",
      "127/127 [==============================] - 4586s 36s/step - loss: 0.0728 - mse: 0.0087 - mae: 0.0728 - val_loss: 0.0635 - val_mse: 0.0069 - val_mae: 0.0635 - lr: 1.0000e-06\n",
      "Epoch 57/512\n",
      "127/127 [==============================] - 5305s 42s/step - loss: 0.0733 - mse: 0.0088 - mae: 0.0733 - val_loss: 0.0635 - val_mse: 0.0069 - val_mae: 0.0635 - lr: 1.0000e-06\n",
      "Epoch 58/512\n",
      "127/127 [==============================] - 4692s 37s/step - loss: 0.0732 - mse: 0.0087 - mae: 0.0732 - val_loss: 0.0636 - val_mse: 0.0069 - val_mae: 0.0636 - lr: 1.0000e-06\n",
      "Epoch 59/512\n",
      "127/127 [==============================] - 5283s 42s/step - loss: 0.0742 - mse: 0.0088 - mae: 0.0742 - val_loss: 0.0635 - val_mse: 0.0069 - val_mae: 0.0635 - lr: 1.0000e-06\n",
      "Epoch 60/512\n",
      "127/127 [==============================] - 3661s 29s/step - loss: 0.0742 - mse: 0.0089 - mae: 0.0742 - val_loss: 0.0636 - val_mse: 0.0069 - val_mae: 0.0636 - lr: 1.0000e-06\n",
      "Epoch 61/512\n",
      "127/127 [==============================] - 5560s 44s/step - loss: 0.0726 - mse: 0.0086 - mae: 0.0726 - val_loss: 0.0635 - val_mse: 0.0069 - val_mae: 0.0635 - lr: 1.0000e-06\n",
      "Epoch 62/512\n",
      "127/127 [==============================] - 3721s 30s/step - loss: 0.0715 - mse: 0.0084 - mae: 0.0715 - val_loss: 0.0635 - val_mse: 0.0069 - val_mae: 0.0635 - lr: 1.0000e-06\n",
      "Epoch 63/512\n",
      "127/127 [==============================] - 4654s 37s/step - loss: 0.0725 - mse: 0.0086 - mae: 0.0725 - val_loss: 0.0634 - val_mse: 0.0069 - val_mae: 0.0634 - lr: 1.0000e-06\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 128, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 128, 128, 48)      480       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 128, 128, 48)      20784     \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 128, 128, 48)      20784     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 128, 128, 48)      389376    \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 48)                0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 48)                192       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 12)                588       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 12)                156       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432373 (1.65 MB)\n",
      "Trainable params: 432277 (1.65 MB)\n",
      "Non-trainable params: 96 (384.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432373\n",
      "Epoch 1/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 19:01:18.735929: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - ETA: 0s - loss: 0.1167 - mse: 0.0237 - mae: 0.1167 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 19:50:11.380903: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 2935s 18s/step - loss: 0.1167 - mse: 0.0237 - mae: 0.1167 - val_loss: 0.5652 - val_mse: 0.4175 - val_mae: 0.5652 - lr: 0.0010\n",
      "Epoch 2/512\n",
      "127/127 [==============================] - 32s 250ms/step - loss: 0.1173 - mse: 0.0257 - mae: 0.1173 - val_loss: 0.2139 - val_mse: 0.0606 - val_mae: 0.2139 - lr: 0.0010\n",
      "Epoch 3/512\n",
      "127/127 [==============================] - 32s 253ms/step - loss: 0.0993 - mse: 0.0172 - mae: 0.0993 - val_loss: 0.3581 - val_mse: 0.1466 - val_mae: 0.3581 - lr: 0.0010\n",
      "Epoch 4/512\n",
      "127/127 [==============================] - 32s 253ms/step - loss: 0.1179 - mse: 0.0253 - mae: 0.1179 - val_loss: 0.4774 - val_mse: 0.2836 - val_mae: 0.4774 - lr: 0.0010\n",
      "Epoch 5/512\n",
      "127/127 [==============================] - 32s 250ms/step - loss: 0.0913 - mse: 0.0135 - mae: 0.0913 - val_loss: 0.4057 - val_mse: 0.2404 - val_mae: 0.4057 - lr: 0.0010\n",
      "Epoch 6/512\n",
      "127/127 [==============================] - 32s 251ms/step - loss: 0.1131 - mse: 0.0220 - mae: 0.1131 - val_loss: 0.4213 - val_mse: 0.2642 - val_mae: 0.4213 - lr: 0.0010\n",
      "Epoch 7/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0924 - mse: 0.0138 - mae: 0.0924 - val_loss: 0.5337 - val_mse: 0.3553 - val_mae: 0.5337 - lr: 0.0010\n",
      "Epoch 8/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0950 - mse: 0.0146 - mae: 0.0950 - val_loss: 0.2544 - val_mse: 0.0858 - val_mae: 0.2544 - lr: 1.0000e-04\n",
      "Epoch 9/512\n",
      "127/127 [==============================] - 32s 250ms/step - loss: 0.0783 - mse: 0.0100 - mae: 0.0783 - val_loss: 0.0673 - val_mse: 0.0073 - val_mae: 0.0673 - lr: 1.0000e-04\n",
      "Epoch 10/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0780 - mse: 0.0100 - mae: 0.0780 - val_loss: 0.1144 - val_mse: 0.0184 - val_mae: 0.1144 - lr: 1.0000e-04\n",
      "Epoch 11/512\n",
      "127/127 [==============================] - 32s 250ms/step - loss: 0.0799 - mse: 0.0105 - mae: 0.0799 - val_loss: 0.2111 - val_mse: 0.0590 - val_mae: 0.2111 - lr: 1.0000e-04\n",
      "Epoch 12/512\n",
      "127/127 [==============================] - 32s 250ms/step - loss: 0.0828 - mse: 0.0116 - mae: 0.0828 - val_loss: 0.4274 - val_mse: 0.2223 - val_mae: 0.4274 - lr: 1.0000e-04\n",
      "Epoch 13/512\n",
      "127/127 [==============================] - 32s 251ms/step - loss: 0.0818 - mse: 0.0112 - mae: 0.0818 - val_loss: 0.1307 - val_mse: 0.0235 - val_mae: 0.1307 - lr: 1.0000e-04\n",
      "Epoch 14/512\n",
      "127/127 [==============================] - 32s 250ms/step - loss: 0.1070 - mse: 0.0186 - mae: 0.1070 - val_loss: 0.1073 - val_mse: 0.0159 - val_mae: 0.1073 - lr: 1.0000e-04\n",
      "Epoch 15/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0772 - mse: 0.0097 - mae: 0.0772 - val_loss: 0.0861 - val_mse: 0.0108 - val_mae: 0.0861 - lr: 1.0000e-05\n",
      "Epoch 16/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0780 - mse: 0.0099 - mae: 0.0780 - val_loss: 0.0767 - val_mse: 0.0090 - val_mae: 0.0767 - lr: 1.0000e-05\n",
      "Epoch 17/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0791 - mse: 0.0103 - mae: 0.0791 - val_loss: 0.0788 - val_mse: 0.0094 - val_mae: 0.0788 - lr: 1.0000e-05\n",
      "Epoch 18/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0805 - mse: 0.0106 - mae: 0.0805 - val_loss: 0.0737 - val_mse: 0.0087 - val_mae: 0.0737 - lr: 1.0000e-05\n",
      "Epoch 19/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0802 - mse: 0.0105 - mae: 0.0802 - val_loss: 0.0777 - val_mse: 0.0094 - val_mae: 0.0777 - lr: 1.0000e-05\n",
      "Epoch 20/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0809 - mse: 0.0106 - mae: 0.0809 - val_loss: 0.0697 - val_mse: 0.0081 - val_mae: 0.0697 - lr: 1.0000e-06\n",
      "Epoch 21/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0780 - mse: 0.0098 - mae: 0.0780 - val_loss: 0.0698 - val_mse: 0.0082 - val_mae: 0.0698 - lr: 1.0000e-06\n",
      "Epoch 22/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0817 - mse: 0.0109 - mae: 0.0817 - val_loss: 0.0703 - val_mse: 0.0083 - val_mae: 0.0703 - lr: 1.0000e-06\n",
      "Epoch 23/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0770 - mse: 0.0098 - mae: 0.0770 - val_loss: 0.0704 - val_mse: 0.0084 - val_mae: 0.0704 - lr: 1.0000e-06\n",
      "Epoch 24/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0774 - mse: 0.0097 - mae: 0.0774 - val_loss: 0.0709 - val_mse: 0.0086 - val_mae: 0.0709 - lr: 1.0000e-06\n",
      "Epoch 25/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0785 - mse: 0.0100 - mae: 0.0785 - val_loss: 0.0711 - val_mse: 0.0086 - val_mae: 0.0711 - lr: 1.0000e-06\n",
      "Epoch 26/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0790 - mse: 0.0101 - mae: 0.0790 - val_loss: 0.0716 - val_mse: 0.0087 - val_mae: 0.0716 - lr: 1.0000e-06\n",
      "Epoch 27/512\n",
      "127/127 [==============================] - 32s 248ms/step - loss: 0.0809 - mse: 0.0107 - mae: 0.0809 - val_loss: 0.0712 - val_mse: 0.0087 - val_mae: 0.0712 - lr: 1.0000e-06\n",
      "Epoch 28/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0790 - mse: 0.0103 - mae: 0.0790 - val_loss: 0.0717 - val_mse: 0.0089 - val_mae: 0.0717 - lr: 1.0000e-06\n",
      "Epoch 29/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0775 - mse: 0.0098 - mae: 0.0775 - val_loss: 0.0717 - val_mse: 0.0090 - val_mae: 0.0717 - lr: 1.0000e-06\n",
      "Epoch 30/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0810 - mse: 0.0107 - mae: 0.0810 - val_loss: 0.0720 - val_mse: 0.0090 - val_mae: 0.0720 - lr: 1.0000e-06\n",
      "Epoch 31/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0783 - mse: 0.0100 - mae: 0.0783 - val_loss: 0.0717 - val_mse: 0.0090 - val_mae: 0.0717 - lr: 1.0000e-06\n",
      "Epoch 32/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0799 - mse: 0.0102 - mae: 0.0799 - val_loss: 0.0721 - val_mse: 0.0091 - val_mae: 0.0721 - lr: 1.0000e-06\n",
      "Epoch 33/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0801 - mse: 0.0107 - mae: 0.0801 - val_loss: 0.0724 - val_mse: 0.0092 - val_mae: 0.0724 - lr: 1.0000e-06\n",
      "Epoch 34/512\n",
      "127/127 [==============================] - 999s 8s/step - loss: 0.0801 - mse: 0.0105 - mae: 0.0801 - val_loss: 0.0725 - val_mse: 0.0093 - val_mae: 0.0725 - lr: 1.0000e-06\n",
      "Epoch 35/512\n",
      "127/127 [==============================] - 32s 248ms/step - loss: 0.0809 - mse: 0.0108 - mae: 0.0809 - val_loss: 0.0729 - val_mse: 0.0095 - val_mae: 0.0729 - lr: 1.0000e-06\n",
      "Epoch 36/512\n",
      "127/127 [==============================] - 995s 8s/step - loss: 0.0815 - mse: 0.0108 - mae: 0.0815 - val_loss: 0.0731 - val_mse: 0.0096 - val_mae: 0.0731 - lr: 1.0000e-06\n",
      "Epoch 37/512\n",
      "127/127 [==============================] - 32s 248ms/step - loss: 0.0823 - mse: 0.0113 - mae: 0.0823 - val_loss: 0.0734 - val_mse: 0.0097 - val_mae: 0.0734 - lr: 1.0000e-06\n",
      "Epoch 38/512\n",
      "127/127 [==============================] - 34s 266ms/step - loss: 0.0811 - mse: 0.0108 - mae: 0.0811 - val_loss: 0.0740 - val_mse: 0.0099 - val_mae: 0.0740 - lr: 1.0000e-06\n",
      "Epoch 39/512\n",
      "127/127 [==============================] - 994s 8s/step - loss: 0.0831 - mse: 0.0112 - mae: 0.0831 - val_loss: 0.0742 - val_mse: 0.0100 - val_mae: 0.0742 - lr: 1.0000e-06\n",
      "Epoch 40/512\n",
      "127/127 [==============================] - 32s 248ms/step - loss: 0.0806 - mse: 0.0107 - mae: 0.0806 - val_loss: 0.0745 - val_mse: 0.0101 - val_mae: 0.0745 - lr: 1.0000e-06\n",
      "Epoch 41/512\n",
      "127/127 [==============================] - 34s 266ms/step - loss: 0.0834 - mse: 0.0115 - mae: 0.0834 - val_loss: 0.0752 - val_mse: 0.0103 - val_mae: 0.0752 - lr: 1.0000e-06\n",
      "Epoch 42/512\n",
      "127/127 [==============================] - 1020s 8s/step - loss: 0.0838 - mse: 0.0117 - mae: 0.0838 - val_loss: 0.0755 - val_mse: 0.0104 - val_mae: 0.0755 - lr: 1.0000e-06\n",
      "Epoch 43/512\n",
      "127/127 [==============================] - 32s 248ms/step - loss: 0.0814 - mse: 0.0108 - mae: 0.0814 - val_loss: 0.0762 - val_mse: 0.0106 - val_mae: 0.0762 - lr: 1.0000e-06\n",
      "Epoch 44/512\n",
      "127/127 [==============================] - 32s 249ms/step - loss: 0.0816 - mse: 0.0110 - mae: 0.0816 - val_loss: 0.0765 - val_mse: 0.0108 - val_mae: 0.0765 - lr: 1.0000e-06\n",
      "Epoch 45/512\n",
      "127/127 [==============================] - 443s 4s/step - loss: 0.0854 - mse: 0.0122 - mae: 0.0854 - val_loss: 0.0772 - val_mse: 0.0110 - val_mae: 0.0772 - lr: 1.0000e-06\n",
      "Epoch 46/512\n",
      "127/127 [==============================] - 976s 8s/step - loss: 0.0847 - mse: 0.0120 - mae: 0.0847 - val_loss: 0.0782 - val_mse: 0.0113 - val_mae: 0.0782 - lr: 1.0000e-06\n",
      "Epoch 47/512\n",
      "127/127 [==============================] - 31s 247ms/step - loss: 0.0844 - mse: 0.0119 - mae: 0.0844 - val_loss: 0.0782 - val_mse: 0.0113 - val_mae: 0.0782 - lr: 1.0000e-06\n",
      "Epoch 48/512\n",
      "127/127 [==============================] - 32s 248ms/step - loss: 0.0833 - mse: 0.0115 - mae: 0.0833 - val_loss: 0.0785 - val_mse: 0.0115 - val_mae: 0.0785 - lr: 1.0000e-06\n",
      "Epoch 49/512\n",
      "127/127 [==============================] - 32s 254ms/step - loss: 0.0850 - mse: 0.0120 - mae: 0.0850 - val_loss: 0.0794 - val_mse: 0.0118 - val_mae: 0.0794 - lr: 1.0000e-06\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 128, 128, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 128, 128, 48)      480       \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 128, 128, 48)      20784     \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 128, 128, 48)      20784     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 128, 128, 48)      2352      \n",
      "                                                                 \n",
      " depthwise_dilation2d (Dept  (None, 128, 128, 48)      8112      \n",
      " hwiseDilation2D)                                                \n",
      "                                                                 \n",
      " global_average_pooling2d_2  (None, 48)                0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 48)                192       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 12)                588       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 12)                156       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53461 (208.83 KB)\n",
      "Trainable params: 53365 (208.46 KB)\n",
      "Non-trainable params: 96 (384.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53461\n",
      "Epoch 1/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 21:42:53.940006: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - ETA: 0s - loss: 0.0987 - mse: 0.0177 - mae: 0.0987 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 22:49:48.059261: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 4085s 32s/step - loss: 0.0987 - mse: 0.0177 - mae: 0.0987 - val_loss: 0.2006 - val_mse: 0.0576 - val_mae: 0.2006 - lr: 0.0010\n",
      "Epoch 2/512\n",
      "127/127 [==============================] - 1300s 10s/step - loss: 0.0792 - mse: 0.0105 - mae: 0.0792 - val_loss: 0.1082 - val_mse: 0.0199 - val_mae: 0.1082 - lr: 0.0010\n",
      "Epoch 3/512\n",
      "127/127 [==============================] - 2960s 23s/step - loss: 0.0720 - mse: 0.0085 - mae: 0.0720 - val_loss: 0.1656 - val_mse: 0.0374 - val_mae: 0.1656 - lr: 0.0010\n",
      "Epoch 4/512\n",
      "127/127 [==============================] - 9964s 79s/step - loss: 0.0774 - mse: 0.0099 - mae: 0.0774 - val_loss: 0.3009 - val_mse: 0.1060 - val_mae: 0.3009 - lr: 0.0010\n",
      "Epoch 5/512\n",
      "127/127 [==============================] - 9044s 72s/step - loss: 0.0764 - mse: 0.0099 - mae: 0.0764 - val_loss: 0.4404 - val_mse: 0.2366 - val_mae: 0.4404 - lr: 0.0010\n",
      "Epoch 6/512\n",
      "127/127 [==============================] - 7783s 62s/step - loss: 0.0766 - mse: 0.0097 - mae: 0.0766 - val_loss: 0.1477 - val_mse: 0.0295 - val_mae: 0.1477 - lr: 0.0010\n",
      "Epoch 7/512\n",
      "127/127 [==============================] - 3940s 31s/step - loss: 0.0760 - mse: 0.0096 - mae: 0.0760 - val_loss: 0.1013 - val_mse: 0.0172 - val_mae: 0.1013 - lr: 0.0010\n",
      "Epoch 8/512\n",
      " 73/127 [================>.............] - ETA: 43:50 - loss: 0.0784 - mse: 0.0104 - mae: 0.0784"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 157\u001b[0m\n\u001b[1;32m    152\u001b[0m CB2\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39mPATIENCE_ES,restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m    153\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(patience\u001b[38;5;241m=\u001b[39mPATIENCE_RP,min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m),\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m#    tf.keras.callbacks.CSVLogger(dir_autosave_model_stat+'Dil', separator=',', append=False)\u001b[39;00m\n\u001b[1;32m    155\u001b[0m    ]\n\u001b[1;32m    156\u001b[0m modelDil\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m histDil\u001b[38;5;241m=\u001b[39m\u001b[43mmodelDil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlistIm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlistY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCB2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlistImVal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlistYVal\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def dilation2d(x, st_element, strides, padding,rates=(1, 1)):\n",
    "    \"\"\"\n",
    "\n",
    "    From MORPHOLAYERS\n",
    "\n",
    "    Basic Dilation Operator\n",
    "    :param st_element: Nonflat structuring element\n",
    "    :strides: strides as classical convolutional layers\n",
    "    :padding: padding as classical convolutional layers\n",
    "    :rates: rates as classical convolutional layers\n",
    "    \"\"\"\n",
    "    x = tf.nn.dilation2d(x, st_element, (1, ) + strides + (1, ),padding.upper(),\"NHWC\",(1,)+rates+(1,))\n",
    "    return x\n",
    "\n",
    "class DepthwiseDilation2D(Layer):\n",
    "    '''\n",
    "    Depthwise Dilation 2D Layer: Depthwise Dilation for now assuming channel last\n",
    "    '''\n",
    "    def __init__(self, kernel_size,depth_multiplier=1, strides=(1, 1),padding='same', dilation_rate=(1,1), kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1., maxval=0.),\n",
    "    kernel_constraint=None,kernel_regularization=None,**kwargs):\n",
    "        super(DepthwiseDilation2D, self).__init__(**kwargs)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.depth_multiplier= depth_multiplier\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.rates=dilation_rate\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.kernel_constraint = tf.keras.constraints.get(kernel_constraint)\n",
    "        self.kernel_regularization = tf.keras.regularizers.get(kernel_regularization)\n",
    "        # for we are assuming channel last\n",
    "        self.channel_axis = -1\n",
    "\n",
    "        # self.output_dim = output_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if input_shape[self.channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "\n",
    "        input_dim = input_shape[self.channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim,self.depth_multiplier)\n",
    "        self.kernel2D = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel2D',constraint =self.kernel_constraint,regularizer=self.kernel_regularization)\n",
    "        super(DepthwiseDilation2D, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        res=[]\n",
    "        for di in range(self.depth_multiplier):\n",
    "            H=tf.nn.dilation2d(x,self.kernel2D[:,:,:,di],strides=(1, ) + self.strides + (1, ),padding=self.padding.upper(),data_format=\"NHWC\",dilations=(1,)+self.rates+(1,))\n",
    "            res.append(H)\n",
    "        return tf.concat(res,axis=-1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "\n",
    "        space = input_shape[1:-1]\n",
    "        new_space = []\n",
    "        for i in range(len(space)):\n",
    "            new_dim = conv_utils.conv_output_length(\n",
    "                space[i],\n",
    "                self.kernel_size[i],\n",
    "                padding=self.padding,\n",
    "                stride=self.strides[i],\n",
    "                dilation=self.rates[i])\n",
    "            new_space.append(new_dim)\n",
    "\n",
    "        return (input_shape[0],) + tuple(new_space) + (self.depth_multiplier,)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'num_filters': self.num_filters,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'depth_multiplier': self.depth_multiplier,\n",
    "            'strides': self.strides,\n",
    "            'padding': self.padding,\n",
    "            'dilation_rate': self.rates,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "\n",
    "xinput = layers.Input(shape=(IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "xconv=xinput\n",
    "for i in range(NLAYERS):\n",
    "    xconv = layers.Conv2D(NFILTERS,(3,3),padding='same',activation='relu')(xconv)\n",
    "if NLAYERS>0:\n",
    "    xconv = layers.Conv2D(NFILTERS//SHRINK,(1,1),padding='same',activation='relu')(xconv)\n",
    "    xconv = layers.DepthwiseConv2D((KSIZE,KSIZE),depth_multiplier=SHRINK,padding='same')(xconv)\n",
    "else:\n",
    "    xconv = layers.DepthwiseConv2D((KSIZE,KSIZE),depth_multiplier=NFILTERS,padding='same')(xconv)\n",
    "xfeatures=layers.GlobalAveragePooling2D()(xconv)\n",
    "xfeatures=layers.BatchNormalization()(xfeatures)\n",
    "xfeatures=layers.Dense(SUBSPACE,'relu')(xfeatures)\n",
    "xfeatures=layers.Dense(SUBSPACE)(xfeatures)\n",
    "xend=layers.Dense(1,activation='sigmoid')(xfeatures)\n",
    "modelDWConv=tf.keras.Model(xinput,xend)\n",
    "modelDWConv.summary()\n",
    "print(modelDWConv.count_params())\n",
    "\n",
    "CBDW=[tf.keras.callbacks.EarlyStopping(patience=PATIENCE_ES,restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience=PATIENCE_RP,min_lr=1e-6),\n",
    "#    tf.keras.callbacks.CSVLogger(dir_autosave_model_stat+'DWConv', separator=',', append=False)\n",
    "   ]\n",
    "modelDWConv.compile(loss=\"mae\", optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate), metrics=[\"mse\",\"mae\"])\n",
    "histDWConv=modelDWConv.fit(listIm, listY, batch_size=batch_size, epochs=epochs,callbacks=CBDW,validation_data=(listImVal, listYVal))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xinput = layers.Input(shape=(IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "xconv=xinput\n",
    "for i in range(NLAYERS):\n",
    "    xconv = layers.Conv2D(NFILTERS,(3,3),padding='same',activation='relu')(xconv)\n",
    "xconv=layers.Conv2D(NFILTERS,(KSIZE,KSIZE),use_bias=False,padding='same')(xconv)\n",
    "xfeatures=layers.GlobalAveragePooling2D()(xconv)\n",
    "xfeatures=layers.BatchNormalization()(xfeatures)\n",
    "xfeatures=layers.Dense(SUBSPACE,'relu')(xfeatures)\n",
    "xfeatures=layers.Dense(SUBSPACE)(xfeatures)\n",
    "xend=layers.Dense(1,activation='sigmoid')(xfeatures)\n",
    "modelConv=tf.keras.Model(xinput,xend)\n",
    "modelConv.summary()\n",
    "print(modelConv.count_params())\n",
    "\n",
    "CB1=[tf.keras.callbacks.EarlyStopping(patience=PATIENCE_ES,restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience=PATIENCE_RP,min_lr=1e-6),\n",
    "#    tf.keras.callbacks.CSVLogger(dir_autosave_model_stat+'Conv', separator=',', append=False)\n",
    "   ]\n",
    "modelConv.compile(loss=\"mae\", optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate), metrics=[\"mse\",\"mae\"])\n",
    "histConv=modelConv.fit(listIm, listY, batch_size=batch_size, epochs=epochs,callbacks=CB1,validation_data=(listImVal, listYVal))\n",
    "\n",
    "\n",
    "xinput = layers.Input(shape=(IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "xconv=xinput\n",
    "for i in range(NLAYERS):\n",
    "    xconv = layers.Conv2D(NFILTERS,(3,3),padding='same',activation='relu')(xconv)\n",
    "if NLAYERS>0:\n",
    "    xconv = layers.Conv2D(NFILTERS//SHRINK,(1,1),padding='same',activation='relu')(xconv)\n",
    "    xconv = DepthwiseDilation2D((KSIZE,KSIZE),depth_multiplier=SHRINK,padding='same')(xconv)\n",
    "else:\n",
    "    xconv = DepthwiseDilation2D((KSIZE,KSIZE),depth_multiplier=NFILTERS,padding='same')(xconv)\n",
    "xfeatures=layers.GlobalAveragePooling2D()(xconv)\n",
    "xfeatures=layers.BatchNormalization()(xfeatures)\n",
    "xfeatures=layers.Dense(SUBSPACE,activation='relu')(xfeatures)\n",
    "xfeatures=layers.Dense(SUBSPACE)(xfeatures)\n",
    "xend=layers.Dense(1,activation='sigmoid')(xfeatures)\n",
    "modelDil=tf.keras.Model(xinput,xend)\n",
    "modelDil.summary()\n",
    "print(modelDil.count_params())\n",
    "\n",
    "CB2=[tf.keras.callbacks.EarlyStopping(patience=PATIENCE_ES,restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience=PATIENCE_RP,min_lr=1e-6),\n",
    "#    tf.keras.callbacks.CSVLogger(dir_autosave_model_stat+'Dil', separator=',', append=False)\n",
    "   ]\n",
    "modelDil.compile(loss=\"mae\", optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate), metrics=[\"mse\",\"mae\"])\n",
    "histDil=modelDil.fit(listIm, listY, batch_size=batch_size, epochs=epochs,callbacks=CB2,validation_data=(listImVal, listYVal))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de97632-5fd4-42af-b98c-256c39e2fa3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0b9b59-e1f8-4f54-9dfe-2cdc47d9f613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
